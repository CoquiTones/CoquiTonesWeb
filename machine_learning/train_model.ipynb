{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SLICE_SECONDS = 10 # Length of input slices for model.\n",
                "FFT_HOP_LENGTH = 512 # How many time domain samples per spectrogram frame\n",
                "SAMPLE_RATE = 22050\n",
                "Y_RESOLUTION = 20\n",
                "\n",
                "n_model_input_parameters = SAMPLE_RATE // FFT_HOP_LENGTH * SLICE_SECONDS * Y_RESOLUTION\n",
                "\n",
                "f\"Model takes {n_model_input_parameters} parameters\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -*- coding: utf-8 -*-\n",
                "\n",
                "# don\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import librosa\n",
                "import os\n",
                "import csv\n",
                "import shutil\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
                "from sklearn.metrics import (\n",
                "    roc_auc_score,        \n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"machine_learning/processed/processed.csv\")\n",
                "df = df.drop(columns='Unnamed: 0')\n",
                "df['E. coqui'] = df['E. coqui - co']\n",
                "df['E. portoricensis'] = df['E. portoricensis - co']\n",
                "df = df.drop(columns=[\n",
                "    'E. coqui - co',\n",
                "    'E. coqui - qui',\n",
                "    'E. portoricensis - co',\n",
                "    'E. portoricensis - qui'\n",
                "])\n",
                "df = df[[\n",
                "    'siteId',\n",
                "    'filename',\n",
                "    'E. coqui',\n",
                "    'E. wightmanae',\n",
                "    'E. gryllus',\n",
                "    'E. portoricensis',\n",
                "    'E. unicolor',\n",
                "    'E. hedricki',\n",
                "    'E. locustus',\n",
                "    'E. richmondi'\n",
                "]]\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_features(file_path):\n",
                "    \"\"\"\n",
                "    Extract spectrogram from audio file using librosa. \n",
                "\n",
                "    Args:\n",
                "        file_path (str): Path to the audio file.\n",
                "\n",
                "    Returns:\n",
                "        np.array: Extracted features.\n",
                "        int: Sample rate in hertz\n",
                "    \"\"\"\n",
                "    audio, sr = librosa.load(file_path)\n",
                "\n",
                "    # MFCC\n",
                "    return librosa.feature.mfcc(y=audio, sr=sr, hop_length = FFT_HOP_LENGTH), sr\n",
                "\n",
                "# Initialize a list to store the results\n",
                "spectrograms = []\n",
                "sample_rates = []\n",
                "\n",
                "with ThreadPoolExecutor() as executor:\n",
                "    futures = [\n",
                "        executor.submit(extract_features, row[\"filename\"])\n",
                "        for _, row in df.iterrows()\n",
                "    ]\n",
                "\n",
                "    for future in as_completed(futures):\n",
                "        try:\n",
                "            spectrogram, sr = future.result()\n",
                "            spectrograms.append(spectrogram)\n",
                "            sample_rates.append(sr)\n",
                "        except Exception as exc:\n",
                "            print(f\"Generated an exception: {exc}\")\n",
                "\n",
                "# Process the spectrograms\n",
                "assert(min(sample_rates) == max(sample_rates))\n",
                "sr = min(sample_rates)\n",
                "slice_width = sr * SLICE_SECONDS // FFT_HOP_LENGTH\n",
                "# Slice them into fixed widths\n",
                "spectrogram_slices = []\n",
                "for spectrogram in spectrograms:    \n",
                "    spectrogram = spectrogram[:, :-(spectrogram.shape[1] % slice_width)] # Take only the section of the spectrogram that will split into fixed slices\n",
                "    n_slices = spectrogram.shape[1] / slice_width\n",
                "    result = np.hsplit(spectrogram, n_slices)\n",
                "    spectrogram_slices.append(result)\n",
                "\n",
                "# Group up the filenames with their corresponding spectrogram slices\n",
                "spectral_data = pd.DataFrame(sum([\n",
                "    [\n",
                "        (filename,) + tuple(spectrogram.flatten()) for spectrogram in spectrograms\n",
                "    ]\n",
                "    for spectrograms, filename in zip(spectrogram_slices, df.filename)\n",
                "], []))\n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the names of the species\n",
                "species_names = list(df.columns.drop(['siteId', 'filename']))\n",
                "# Join the new spectrogram data with the existing dataframe\n",
                "df = df.merge(spectral_data, left_on='filename', right_on=0, how='right').drop(columns=0)\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set up readable index for df\n",
                "df.columns = pd.MultiIndex.from_arrays([   \n",
                "    ['metadata'] * 2 + ['classes'] * len(species_names) + ['spectral'] * (n_model_input_parameters),\n",
                "    ['siteId', 'filename'] + species_names + list(range(n_model_input_parameters))\n",
                "])\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = df['spectral']  # Adjust this to include only feature columns\n",
                "# Convert all column names to strings\n",
                "\n",
                "x"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y = df[\"classes\"].applymap(int)\n",
                "y\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
                "\n",
                "classifier = RandomForestClassifier(n_estimators=600, max_depth=25, min_samples_leaf=3, n_jobs=-1)\n",
                "\n",
                "classifier.fit(x_train, y_train)\n",
                "\n",
                "y_pred = classifier.predict(\n",
                "    x_test,\n",
                ")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prediction_df = pd.DataFrame(y_pred, columns=y_test.columns, index=y_test.index)\n",
                "\n",
                "prediction_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "accuracy_df = prediction_df == y_test\n",
                "accuracy_df.sum() / 69"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "with open(\"./backend/trainedRF.pkl\", \"wb\") as f:\n",
                "    pickle.dump(classifier, f)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}