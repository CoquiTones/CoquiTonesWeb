{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# don\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import zipfile\n",
    "import csv\n",
    "import shutil\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,        \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script for extracting data from https://figshare.com/articles/dataset/Sounds_of_the_Eleutherodactylus_frog_community_from_Puerto_Rico/806302?file=3104183\n",
    "Unzips all the zips from root\n",
    "Simply Unzip downloaded file and provide path root of folder\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def extract_zip_file(file_path, extract_to):\n",
    "    \"\"\"\n",
    "    Extracts a single zip file to a specified directory.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the zip file.\n",
    "        extract_to (str): Path to the directory where the zip file will be extracted.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "        # print(f\"{os.path.basename(file_path)} extracted to {os.path.abspath(extract_to)}\")\n",
    "\n",
    "\n",
    "def extract_zip_files(zip_folder, extract_to):\n",
    "    \"\"\"\n",
    "    Extracts all zip files from a folder to a specified directory using threading.\n",
    "\n",
    "    Args:\n",
    "        zip_folder (str): Path to the folder containing zip files.\n",
    "        extract_to (str): Path to the directory where zip files will be extracted.\n",
    "    \"\"\"\n",
    "    # Make sure the extraction directory exists\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "    data_file = \"FrequencyRange_by_species_and_site_Averages.csv\"\n",
    "    shutil.copyfile(os.path.join(zip_folder, data_file) , os.path.join(extract_to, data_file))\n",
    "\n",
    "    # List all zip files in the folder\n",
    "    zip_files = [\n",
    "        os.path.join(zip_folder, item)\n",
    "        for item in os.listdir(zip_folder)\n",
    "        if item.endswith(\".zip\")\n",
    "    ]\n",
    "\n",
    "    # Use ThreadPoolExecutor to extract zip files concurrently\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(extract_zip_file, zip_file, extract_to)\n",
    "            for zip_file in zip_files\n",
    "        ]\n",
    "\n",
    "        # Wait for all futures to complete\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "    \n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/home/edwinc/Downloads/806302\"\n",
    "ExtractTo = \"/home/edwinc/Downloads/806302/Extracted\"\n",
    "extract_zip_files(filepath, ExtractTo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAveragesData(path: str):\n",
    "\n",
    "    data = []\n",
    "    # Read the CSV file and store the data in a list of dictionaries\n",
    "    with open(path, \"r\") as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def prepare_csv(data_dir, output) -> None:\n",
    "\n",
    "    \n",
    "    averagesData = readAveragesData(\n",
    "        os.path.join(data_dir, \"FrequencyRange_by_species_and_site_Averages.csv\")\n",
    "    )\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Iterate through each subfolder\n",
    "    for siteDataSet in os.listdir(data_dir):\n",
    "        site_folder = os.path.join(data_dir, siteDataSet)\n",
    "        if os.path.isdir(site_folder):\n",
    "            # example siteId  \"Site01-1\" such that the 4-6 index represents the site id; in this case 01\n",
    "            siteId = int(siteDataSet[4:6])\n",
    "            SiteData = [\n",
    "                averageClassification\n",
    "                for averageClassification in averagesData\n",
    "                if int(averageClassification[\"SiteID\"]) == siteId\n",
    "            ]\n",
    "\n",
    "            classifications = \", \".join(\n",
    "                [classification[\"Species\"] for classification in SiteData]\n",
    "            )\n",
    "            for audio_recording in os.listdir(site_folder):\n",
    "                if audio_recording.endswith(\".wav\"):\n",
    "                    audio_recording_abs_path = os.path.abspath(\n",
    "                        os.path.join(site_folder, audio_recording)\n",
    "                    )\n",
    "\n",
    "                    data.append([siteId, audio_recording_abs_path, classifications])\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        data,\n",
    "        columns=[\n",
    "            \"siteId\",\n",
    "            \"filename\",\n",
    "            \"species\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    df.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = ExtractTo\n",
    "output = \"machine_learning/processed/processed.csv\"\n",
    "prepare_csv(data_dir, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    \"\"\"\n",
    "    Extract features from audio file using librosa.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the audio file.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Extracted features.\n",
    "    \"\"\"\n",
    "    audio, sr = librosa.load(file_path)\n",
    "    result = np.array([])\n",
    "\n",
    "    # MFCC\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sr).T, axis=0)\n",
    "    result = np.hstack((result, mfccs))\n",
    "\n",
    "    # Chroma\n",
    "    stft = np.abs(librosa.stft(audio))\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T, axis=0)\n",
    "    result = np.hstack((result, chroma))\n",
    "\n",
    "    # Mel-scaled spectrogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=audio, sr=sr).T, axis=0)\n",
    "    result = np.hstack((result, mel))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_data(data_csv_path):\n",
    "    \"\"\"Read Csv with fileanme and generate spectrogram for each sample\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: dataframe with all data\n",
    "    \"\"\"\n",
    "    # data_csv_path = sys.argv[1]\n",
    "\n",
    "    df = pd.read_csv(data_csv_path)\n",
    "\n",
    "    # Initialize a list to store the results\n",
    "    spectrograms = []\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(extract_features, row[\"filename\"])\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                spectrogram = future.result()\n",
    "                spectrograms.append(spectrogram)\n",
    "            except Exception as exc:\n",
    "                print(f\"Generated an exception: {exc}\")\n",
    "\n",
    "    # Convert the list of spectrograms into a DataFrame\n",
    "    spectrogram_df = pd.DataFrame(spectrograms)\n",
    "\n",
    "    # Concatenate the original DataFrame with the new DataFrame containing spectrograms\n",
    "    df = pd.concat([df, spectrogram_df], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siteId</th>\n",
       "      <th>filename</th>\n",
       "      <th>species</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>/home/edwinc/Downloads/806302/Extracted/Site03...</td>\n",
       "      <td>E. coqui - co, E. coqui - qui, E. gryllus, E. ...</td>\n",
       "      <td>-204.848251</td>\n",
       "      <td>131.633331</td>\n",
       "      <td>-55.604843</td>\n",
       "      <td>64.099342</td>\n",
       "      <td>-0.086645</td>\n",
       "      <td>4.280726</td>\n",
       "      <td>28.252939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.840367e-06</td>\n",
       "      <td>2.688746e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>/home/edwinc/Downloads/806302/Extracted/Site03...</td>\n",
       "      <td>E. coqui - co, E. coqui - qui, E. gryllus, E. ...</td>\n",
       "      <td>-209.817902</td>\n",
       "      <td>145.711716</td>\n",
       "      <td>-62.136204</td>\n",
       "      <td>58.966694</td>\n",
       "      <td>-2.604534</td>\n",
       "      <td>3.186882</td>\n",
       "      <td>28.051863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.123617e-06</td>\n",
       "      <td>9.405731e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>/home/edwinc/Downloads/806302/Extracted/Site03...</td>\n",
       "      <td>E. coqui - co, E. coqui - qui, E. gryllus, E. ...</td>\n",
       "      <td>-219.265167</td>\n",
       "      <td>116.345963</td>\n",
       "      <td>-58.627560</td>\n",
       "      <td>62.047398</td>\n",
       "      <td>-6.808269</td>\n",
       "      <td>10.797720</td>\n",
       "      <td>26.177841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>4.967286e-06</td>\n",
       "      <td>4.306051e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/home/edwinc/Downloads/806302/Extracted/Site03...</td>\n",
       "      <td>E. coqui - co, E. coqui - qui, E. gryllus, E. ...</td>\n",
       "      <td>-204.993912</td>\n",
       "      <td>134.253296</td>\n",
       "      <td>-38.925591</td>\n",
       "      <td>61.476059</td>\n",
       "      <td>-17.941975</td>\n",
       "      <td>-3.416336</td>\n",
       "      <td>31.911119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4.315103e-06</td>\n",
       "      <td>4.778029e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>/home/edwinc/Downloads/806302/Extracted/Site03...</td>\n",
       "      <td>E. coqui - co, E. coqui - qui, E. gryllus, E. ...</td>\n",
       "      <td>-229.271957</td>\n",
       "      <td>135.000778</td>\n",
       "      <td>-58.928051</td>\n",
       "      <td>47.495621</td>\n",
       "      <td>2.579341</td>\n",
       "      <td>5.440523</td>\n",
       "      <td>29.769083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.509618e-07</td>\n",
       "      <td>8.347875e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   siteId                                           filename  \\\n",
       "0       3  /home/edwinc/Downloads/806302/Extracted/Site03...   \n",
       "1       3  /home/edwinc/Downloads/806302/Extracted/Site03...   \n",
       "2       3  /home/edwinc/Downloads/806302/Extracted/Site03...   \n",
       "3       3  /home/edwinc/Downloads/806302/Extracted/Site03...   \n",
       "4       3  /home/edwinc/Downloads/806302/Extracted/Site03...   \n",
       "\n",
       "                                             species           0           1  \\\n",
       "0  E. coqui - co, E. coqui - qui, E. gryllus, E. ... -204.848251  131.633331   \n",
       "1  E. coqui - co, E. coqui - qui, E. gryllus, E. ... -209.817902  145.711716   \n",
       "2  E. coqui - co, E. coqui - qui, E. gryllus, E. ... -219.265167  116.345963   \n",
       "3  E. coqui - co, E. coqui - qui, E. gryllus, E. ... -204.993912  134.253296   \n",
       "4  E. coqui - co, E. coqui - qui, E. gryllus, E. ... -229.271957  135.000778   \n",
       "\n",
       "           2          3          4          5          6  ...       150  \\\n",
       "0 -55.604843  64.099342  -0.086645   4.280726  28.252939  ...  0.000021   \n",
       "1 -62.136204  58.966694  -2.604534   3.186882  28.051863  ...  0.000009   \n",
       "2 -58.627560  62.047398  -6.808269  10.797720  26.177841  ...  0.000037   \n",
       "3 -38.925591  61.476059 -17.941975  -3.416336  31.911119  ...  0.000030   \n",
       "4 -58.928051  47.495621   2.579341   5.440523  29.769083  ...  0.000006   \n",
       "\n",
       "        151       152       153       154       155       156       157  \\\n",
       "0  0.000017  0.000015  0.000013  0.000011  0.000009  0.000008  0.000006   \n",
       "1  0.000008  0.000007  0.000006  0.000005  0.000004  0.000003  0.000002   \n",
       "2  0.000032  0.000027  0.000023  0.000020  0.000017  0.000015  0.000011   \n",
       "3  0.000024  0.000020  0.000017  0.000015  0.000012  0.000010  0.000008   \n",
       "4  0.000005  0.000005  0.000005  0.000004  0.000003  0.000002  0.000002   \n",
       "\n",
       "            158           159  \n",
       "0  2.840367e-06  2.688746e-07  \n",
       "1  1.123617e-06  9.405731e-08  \n",
       "2  4.967286e-06  4.306051e-07  \n",
       "3  4.315103e-06  4.778029e-07  \n",
       "4  7.509618e-07  8.347875e-08  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dir = output\n",
    "df = process_data(csv_dir)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['sideId'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m x = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfilename\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspecies\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msideId\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust this to include only feature columns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Convert all column names to strings\u001b[39;00m\n\u001b[32m      5\u001b[39m x.columns = x.columns.astype(\u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/wqv680ffnlcjz5rmpa3kk7bcf1hf9pqi-python3-3.12.10-env/lib/python3.12/site-packages/pandas/core/frame.py:5581\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5435\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5442\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5443\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5445\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5446\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5579\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5583\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5587\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5588\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/wqv680ffnlcjz5rmpa3kk7bcf1hf9pqi-python3-3.12.10-env/lib/python3.12/site-packages/pandas/core/generic.py:4788\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4788\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4791\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/wqv680ffnlcjz5rmpa3kk7bcf1hf9pqi-python3-3.12.10-env/lib/python3.12/site-packages/pandas/core/generic.py:4830\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4828\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4829\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4830\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4831\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4833\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4834\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/wqv680ffnlcjz5rmpa3kk7bcf1hf9pqi-python3-3.12.10-env/lib/python3.12/site-packages/pandas/core/indexes/base.py:7070\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7068\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7071\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['sideId'] not found in axis\""
     ]
    }
   ],
   "source": [
    "x = df.drop(\n",
    "    columns=[\"filename\", \"species\", \"siteId\"]\n",
    ")  # Adjust this to include only feature columns\n",
    "# Convert all column names to strings\n",
    "x.columns = x.columns.astype(str)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E. coqui - co, E. coqui - qui': np.int64(0),\n",
       " 'E. coqui - co, E. coqui - qui, E. gryllus, E. locustus': np.int64(1),\n",
       " 'E. coqui - co, E. coqui - qui, E. gryllus, E. portoricensis - co, E. portoricensis - qui, E. unicolor': np.int64(2),\n",
       " 'E. coqui - co, E. coqui - qui, E. hedricki': np.int64(3),\n",
       " 'E. coqui - co, E. coqui - qui, E. hedricki, E. portoricensis - co, E. portoricensis - qui': np.int64(4),\n",
       " 'E. coqui - co, E. coqui - qui, E. hedricki, E. portoricensis - co, E. portoricensis - qui, E. unicolor': np.int64(5),\n",
       " 'E. coqui - co, E. coqui - qui, E. portoricensis - co, E. portoricensis - qui, E. richmondi': np.int64(6),\n",
       " 'E. coqui - co, E. coqui - qui, E. portoricensis - co, E. portoricensis - qui, E. unicolor': np.int64(7),\n",
       " 'E. coqui - co, E. coqui - qui, E. richmondi': np.int64(8),\n",
       " 'E. coqui - co, E. coqui - qui, E. richmondi, E. wightmanae': np.int64(9),\n",
       " 'E. coqui - co, E. coqui - qui, E. wightmanae': np.int64(10)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"species\"]\n",
    "\n",
    "# Encode the target labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "le_bron = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "le_bron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9948199735973198\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=600, max_depth=18, min_samples_leaf=3)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict_proba(\n",
    "    x_test,\n",
    ")\n",
    "\n",
    "accuracy = roc_auc_score(y_test, y_pred, multi_class=\"ovr\")\n",
    "print(\"Accuracy :\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../backend/trainedRF.pkl\", \"wb\") as f:\n",
    "    pickle.dump(classifier, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
