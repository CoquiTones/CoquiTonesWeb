{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77997c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import csv\n",
    "import shutil\n",
    "import functools\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93da186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script for extracting data from https://figshare.com/articles/dataset/Sounds_of_the_Eleutherodactylus_frog_community_from_Puerto_Rico/806302?file=3104183\n",
    "Unzips all the zips from root\n",
    "Simply Unzip downloaded file and provide path root of folder\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def extract_zip_file(file_path, extract_to):\n",
    "    \"\"\"\n",
    "    Extracts a single zip file to a specified directory.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the zip file.\n",
    "        extract_to (str): Path to the directory where the zip file will be extracted.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "        # print(f\"{os.path.basename(file_path)} extracted to {os.path.abspath(extract_to)}\")\n",
    "\n",
    "\n",
    "def extract_zip_files(zip_folder, extract_to):\n",
    "    \"\"\"\n",
    "    Extracts all zip files from a folder to a specified directory using threading.\n",
    "\n",
    "    Args:\n",
    "        zip_folder (str): Path to the folder containing zip files.\n",
    "        extract_to (str): Path to the directory where zip files will be extracted.\n",
    "    \"\"\"\n",
    "    # Make sure the extraction directory exists\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "    data_file = \"FrequencyRange_by_species_and_site_Averages.csv\"\n",
    "    shutil.copyfile(os.path.join(zip_folder, data_file) , os.path.join(extract_to, data_file))\n",
    "\n",
    "    # List all zip files in the folder\n",
    "    zip_files = [\n",
    "        os.path.join(zip_folder, item)\n",
    "        for item in os.listdir(zip_folder)\n",
    "        if item.endswith(\".zip\")\n",
    "    ]\n",
    "\n",
    "    # Use ThreadPoolExecutor to extract zip files concurrently\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(extract_zip_file, zip_file, extract_to)\n",
    "            for zip_file in zip_files\n",
    "        ]\n",
    "\n",
    "        # Wait for all futures to complete\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "    \n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/home/edwinc/Downloads/806302\"\n",
    "ExtractTo = \"/home/edwinc/Downloads/806302/Extracted\"\n",
    "extract_zip_files(filepath, ExtractTo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a58e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the AllData file\n",
    "all_data_path = os.path.join(filepath, \"FrequencyRange_by_species_and_site_AllData.csv\")\n",
    "with open(all_data_path, mode=\"r\") as all_data_file:\n",
    "    reader = csv.DictReader(all_data_file)\n",
    "    root_df = pd.DataFrame.from_records(list(reader))\n",
    "root_df = root_df.drop(columns=[None])\n",
    "root_df.SoundID = pd.to_numeric(root_df.SoundID)\n",
    "root_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea4889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now go through all the data.csv files to match the SoundID in our dataframe to a sound file\n",
    "# Find all data.csv files\n",
    "zip_walk = list(os.walk(ExtractTo))\n",
    "leaf_paths = [os.path.join(trace[0], 'data.csv') for trace in zip_walk if 'data.csv' in trace[2]]\n",
    "fragments = [pd.read_csv(leaf_path)[['SoundID', 'SiteID', 'Filename']].drop_duplicates() for leaf_path in leaf_paths]\n",
    "\n",
    "soundid_to_filename = pd.concat(fragments)\n",
    "soundid_to_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the filename to be an absolute path\n",
    "# Since the current Filename column only has the filename and there is no information that directly tells us what directory those files will be in, we must search for them manually\n",
    "# Instead of doing it O(N^2) by searching through all of them n times, we'll just use the os.walk we already performed\n",
    "def update_return(d1, d2):\n",
    "    d1.update(d2)\n",
    "    return d1\n",
    "filename_dict = functools.reduce(\n",
    "    update_return,\n",
    "    [\n",
    "    {\n",
    "        filename: os.path.join(trace[0], filename)\n",
    "        for filename in trace[2]\n",
    "        if filename.endswith('.wav')\n",
    "    }\n",
    "    for trace in zip_walk[1:]\n",
    "])\n",
    "\n",
    "soundid_to_filename.Filename = soundid_to_filename.Filename.apply(lambda x: filename_dict[x])\n",
    "soundid_to_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merge them and save the result\n",
    "preprocess_final = pd.merge(root_df, soundid_to_filename, on=\"SoundID\", validate=\"many_to_one\")[['SiteID_x', 'Filename', 'Species']]\n",
    "preprocess_final.columns = pd.Index(['siteId', 'filename', 'species'])\n",
    "\n",
    "preprocess_final.siteId = pd.to_numeric(preprocess_final.siteId)\n",
    "\n",
    "species_classes = list(preprocess_final['species'].unique())\n",
    "\n",
    "final_output = preprocess_final[['siteId', 'filename']].drop_duplicates()\n",
    "for species in species_classes:\n",
    "    # For each species, make a new column in the dataframe that says which files contain that species\n",
    "    final_output[species] = [\n",
    "        species in set(preprocess_final[preprocess_final['filename'] == filename]['species']) \n",
    "        for filename in final_output['filename']\n",
    "    ]\n",
    "\n",
    "try:\n",
    "    output_path = \"processed/processed.csv\"\n",
    "    final_output.to_csv(output_path)\n",
    "except OSError:\n",
    "    output_path = \"machine_learning/processed/processed.csv\"\n",
    "    final_output.to_csv(output_path)\n",
    "final_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
