{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# don\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import zipfile\n",
    "import csv\n",
    "import shutil\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,        \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script for extracting data from https://figshare.com/articles/dataset/Sounds_of_the_Eleutherodactylus_frog_community_from_Puerto_Rico/806302?file=3104183\n",
    "Unzips all the zips from root\n",
    "Simply Unzip downloaded file and provide path root of folder\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def extract_zip_file(file_path, extract_to):\n",
    "    \"\"\"\n",
    "    Extracts a single zip file to a specified directory.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the zip file.\n",
    "        extract_to (str): Path to the directory where the zip file will be extracted.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "        # print(f\"{os.path.basename(file_path)} extracted to {os.path.abspath(extract_to)}\")\n",
    "\n",
    "\n",
    "def extract_zip_files(zip_folder, extract_to):\n",
    "    \"\"\"\n",
    "    Extracts all zip files from a folder to a specified directory using threading.\n",
    "\n",
    "    Args:\n",
    "        zip_folder (str): Path to the folder containing zip files.\n",
    "        extract_to (str): Path to the directory where zip files will be extracted.\n",
    "    \"\"\"\n",
    "    # Make sure the extraction directory exists\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "    data_file = \"FrequencyRange_by_species_and_site_Averages.csv\"\n",
    "    shutil.copyfile(os.path.join(zip_folder, data_file) , os.path.join(extract_to, data_file))\n",
    "\n",
    "    # List all zip files in the folder\n",
    "    zip_files = [\n",
    "        os.path.join(zip_folder, item)\n",
    "        for item in os.listdir(zip_folder)\n",
    "        if item.endswith(\".zip\")\n",
    "    ]\n",
    "\n",
    "    # Use ThreadPoolExecutor to extract zip files concurrently\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(extract_zip_file, zip_file, extract_to)\n",
    "            for zip_file in zip_files\n",
    "        ]\n",
    "\n",
    "        # Wait for all futures to complete\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "    \n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/home/edwin/Downloads/806302\"\n",
    "ExtractTo = \"/home/edwin/Downloads/806302/Extracted\"\n",
    "extract_zip_files(filepath, ExtractTo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAveragesData(path: str):\n",
    "\n",
    "    data = []\n",
    "    # Read the CSV file and store the data in a list of dictionaries\n",
    "    with open(path, \"r\") as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def prepare_csv(data_dir, output) -> None:\n",
    "\n",
    "    \n",
    "    averagesData = readAveragesData(\n",
    "        os.path.join(data_dir, \"FrequencyRange_by_species_and_site_Averages.csv\")\n",
    "    )\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Iterate through each subfolder\n",
    "    for siteDataSet in os.listdir(data_dir):\n",
    "        site_folder = os.path.join(data_dir, siteDataSet)\n",
    "        if os.path.isdir(site_folder):\n",
    "            # example siteId  \"Site01-1\" such that the 4-6 index represents the site id; in this case 01\n",
    "            siteId = int(siteDataSet[4:6])\n",
    "            SiteData = [\n",
    "                averageClassification\n",
    "                for averageClassification in averagesData\n",
    "                if int(averageClassification[\"SiteID\"]) == siteId\n",
    "            ]\n",
    "\n",
    "            classifications = \", \".join(\n",
    "                [classification[\"Species\"] for classification in SiteData]\n",
    "            )\n",
    "            for audio_recording in os.listdir(site_folder):\n",
    "                if audio_recording.endswith(\".wav\"):\n",
    "                    audio_recording_abs_path = os.path.abspath(\n",
    "                        os.path.join(site_folder, audio_recording)\n",
    "                    )\n",
    "\n",
    "                    data.append([siteId, audio_recording_abs_path, classifications])\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        data,\n",
    "        columns=[\n",
    "            \"siteId\",\n",
    "            \"filename\",\n",
    "            \"species\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    df.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = ExtractTo\n",
    "output = \"processed/processed.csv\"\n",
    "prepare_csv(data_dir, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    \"\"\"\n",
    "    Extract features from audio file using librosa.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the audio file.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Extracted features.\n",
    "    \"\"\"\n",
    "    audio, sr = librosa.load(file_path)\n",
    "    result = np.array([])\n",
    "\n",
    "    # MFCC\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sr).T, axis=0)\n",
    "    result = np.hstack((result, mfccs))\n",
    "\n",
    "    # Chroma\n",
    "    stft = np.abs(librosa.stft(audio))\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T, axis=0)\n",
    "    result = np.hstack((result, chroma))\n",
    "\n",
    "    # Mel-scaled spectrogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=audio, sr=sr).T, axis=0)\n",
    "    result = np.hstack((result, mel))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_data(data_csv_path):\n",
    "    \"\"\"Read Csv with fileanme and generate spectrogram for each sample\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: dataframe with all data\n",
    "    \"\"\"\n",
    "    # data_csv_path = sys.argv[1]\n",
    "\n",
    "    df = pd.read_csv(data_csv_path)\n",
    "\n",
    "    # Initialize a list to store the results\n",
    "    spectrograms = []\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(extract_features, row[\"filename\"])\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                spectrogram = future.result()\n",
    "                spectrograms.append(spectrogram)\n",
    "            except Exception as exc:\n",
    "                print(f\"Generated an exception: {exc}\")\n",
    "\n",
    "    # Convert the list of spectrograms into a DataFrame\n",
    "    spectrogram_df = pd.DataFrame(spectrograms)\n",
    "\n",
    "    # Concatenate the original DataFrame with the new DataFrame containing spectrograms\n",
    "    df = pd.concat([df, spectrogram_df], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = output\n",
    "df = process_data(csv_dir)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\n",
    "    columns=[\"filename\", \"species\"]\n",
    ")  # Adjust this to include only feature columns\n",
    "# Convert all column names to strings\n",
    "x.columns = x.columns.astype(str)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"species\"]\n",
    "\n",
    "# Encode the target labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "le_bron = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "le_bron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=600, max_depth=18, min_samples_leaf=3)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict_proba(\n",
    "    x_test,\n",
    ")\n",
    "\n",
    "accuracy = roc_auc_score(y_test, y_pred, multi_class=\"ovr\")\n",
    "print(\"Accuracy :\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../Backend/trainedRF.pkl\", \"wb\") as f:\n",
    "    pickle.dump(classifier, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
